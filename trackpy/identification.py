#Copyright 2013 Thomas A Caswell
#tcaswell@uchicago.edu
#http://jfi.uchicago.edu/~tcaswell
#
#This program is free software; you can redistribute it and/or modify
#it under the terms of the GNU General Public License as published by
#the Free Software Foundation; either version 3 of the License, or (at
#your option) any later version.
#
#This program is distributed in the hope that it will be useful, but
#WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
#General Public License for more details.
#
#You should have received a copy of the GNU General Public License
#along with this program; if not, see <http://www.gnu.org/licenses>.
from __future__ import division

import numpy as np
import numpy.random as npr
from scipy import ndimage

import itertools


def find_local_max(img, d_rad, threshold=1e-15):
    """
    This is effectively a replacement for pkfnd in the matlab/IDL code.

    The output of this function is meant to be feed into :py:func:`~subpixel_centroid`

    The magic of numpy means this should work for any dimension data.

    :param img: an ndarray representing the data to find the local maxes
    :param d_rad: the radius of the dilation, the smallest possible spacing between local maximum
    :param threshold: optional, voxels < threshold are ignored.

    :rtype: (d,N) array of the local maximums.
    """
    d_rad = int(d_rad)
    img = np.array(np.squeeze(img))       # knock out singleton dimensions
    img[img < threshold] = -np.inf        # mask out pixels below threshold
    dim = img.ndim                        # get the dimension of data

    # make structuring element
    s = ndimage.generate_binary_structure(dim, 1)
    # scale it up to the desired size
    d_struct = ndimage.iterate_structure(s, int(d_rad))
    dilated_img = ndimage.grey_dilation(img,
                                        footprint=d_struct,
                                        cval=0,
                                        mode='constant')   # do the dilation

    # find the locations that are the local maximum
    # TODO clean this up
    local_max = np.where(np.exp(img - dilated_img) > (1 - 1e-15))
    return np.vstack(local_max)


def subpixel_centroid(img, local_maxes, mask_rad):
    '''
    This is effectively a replacement for cntrd in the matlab/IDL code.

    Should work for any dimension data


    :param img: the data
    :param local_maxes: a (d,N) array with the location of the local maximums (as generated by :py:func:`~find_local_max`)
    :param mask_rad: the radius of the mask used for the averaging.

    :rtype: (d,N) array of positions, (d,) array of masses, (d,) array of r2,
    '''
    # do some data checking/munging
    mask_rad = int(mask_rad)
    img = np.squeeze(img)                 # knock out singleton dimensions
    # make sure local_maxes.shape makes sense
    dim = img.ndim
    s = ndimage.generate_binary_structure(dim, 1)
    # scale it up to the desired size
    d_struct = ndimage.iterate_structure(s, int(mask_rad))

    so = [slice(-mask_rad, mask_rad + 1)] * dim
    offset_masks = [d_struct * os for os in np.mgrid[so]]

    r2_mask = np.zeros(d_struct.shape)
    for o in offset_masks:
        r2_mask += o ** 2

    r2_mask = np.sqrt(r2_mask)

    shifts_lst = []
    mass_lst = []
    r2_lst = []
    for loc in itertools.izip(*local_maxes):

        window = [slice(p - mask_rad, p + mask_rad + 1) for p in loc]
        img_win = img[window]
        mass = np.sum(img_win * d_struct)
        mass_lst.append(mass)
        shifts_lst.append([np.sum(img_win * o) / mass for o in offset_masks])
        r2_lst.append(np.sum(r2_mask * img_win))

    return np.array(shifts_lst).T + local_maxes, mass_lst, r2_lst


def band_pass(img, p_rad, hwhm):
    '''
    Intended to be a replacement for bpass in the matlab/IDL code.

    Works by convolving a Gaussian with the image, than a box car and
    taking the difference.

    :param img: array of data
    :param p_rad: the size of the window used for the convolution
    :param hwhm: the hwhm of the Gaussian
    :rtype: :class:`numpy.ndarray` scaled between 0 and 1
    '''
    # make sure the input data is an array and float type.
    img = np.asarray(img).astype(float)

    p_dia = 2 * p_rad + 1

    # do the two convolutions.
    # These should maybe be replaced with masked kernels, but this is
    # faster to code up.
    img_boxcar = ndimage.filters.uniform_filter(img, p_dia, mode='nearest', cval=0)
    img_gaus = ndimage.filters.gaussian_filter(img, hwhm, mode='nearest', cval=0)

    # subtract them
    ret_img = img_boxcar - img_gaus

    # kill data at edegs where the convolution leaked out
    ret_img[ret_img < 0] = 0
    ret_img[:p_dia, :] = 0
    ret_img[-p_dia:, :] = 0
    ret_img[:, :p_dia] = 0
    ret_img[:, -p_dia:] = 0

    # normalize the image
    ret_img -= np.min(ret_img)
    ret_img /= np.max(ret_img)

    return ret_img


def gen_fake_data(list_of_locs, p_rad, hwhm, img_shape):
    """
    Function to generate fake images for testing purposes
    """
    img = np.zeros(img_shape)

    def pixel_values(window, loc):
        i = np.mgrid[window] - loc.reshape(len(window), *[1] * len(window))
        r = np.zeros(i[0].shape)
        for _ in i:
            r += _ ** 2

        return np.exp(-r / (hwhm ** 2))

    for loc in itertools.izip(*list_of_locs):
        window = [slice(int(p) - (p_rad + 2), int(p) + (p_rad + 2) + 1) for p in loc]

        p = pixel_values(window, np.array(loc))
        img[window] += p

    img *= 5
    img += npr.randn(*img.shape) * .1

    return img
